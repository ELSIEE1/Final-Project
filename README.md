# Final-Project
Introduction

We decided to use two Python-based Chatbot datasets and merged them together into one code snippet on Google Colab.

Dataset 1:https://github.com/MaryemSamet/NLP/blob/main/intents.json

Dataset 2:https://www.kaggle.com/datasets/damerajee/simple-chatbot-dataset?utm_source=chatgpt.com

This chatbot is specifically aimed to help answer general questions the user may have. We selected these two datasets because they are alike, both containing a diverse set of questions and responses that the chatbot will be able to use in order to have conversations with the user. The datasets interest us since we’ll be able to train the chatbot to engage in real-world interactions, such as greetings, poems, discussing math puzzles and more. Our goal is to improve the chatbot’s functionality, accuracy, and speed. 

Dataset
For our Chatbot project, we performed many data visualizations. For instance, we generated a chart for tag distribution to show the frequency counts per intent category. We also did a chart for patterns per intent. We visualized the top 20 most frequent words and distribution of labels. This allowed for us to see the most common words and phrases. Also, we generated a word cloud, heatmap of pattern lengths, and box plot of response lengths across intents. From this, we were able to see the pattern lengths across intents and compare the response lengths as well. A bar graph was used to compare patterns and responses per intent. A histogram was used to compare pattern lengths. We used a scatter plot to display pattern vs. response lengths. We also generated bar charts to compare the model size after quantization. 
For data preprocessing, synonym replacement augmentation was performed, so that there’s a diversity of words that can be used to train the model. We also applied tokenization where each sentence was broken into words. Then, the words are converted to lowercase, allowing for uniformity across inputs. Lemmatization was performed to reduce the words to their base form. Using exclude_words allowed for punctuation marks to be removed. We made sure to structure the intents with their corresponding patterns and responses, so that the Chatbot model would be able to accurately associate the user’s input with the correct response. To have a clean dataset, we performed noise and duplication removal. Bag-of-words was used to convert each sentence into a list of 0s and 1s so that it would be able to detect which words are in the sentence. Additionally, one-hot encoding was used so that each intent could be represented as a unique vector, meaning that only one position is 1, while the rest are 0.
For data loading, since the dataset was already available directly in Google Colab, we just had to reference it through the intents variable. It’s in a JSON-like format that has a list of intents, tags, patterns, and responses. This allowed for us to easily access and manipulate/preprocess the data so we could train and evaluate our model. The patterns extracted as input samples and their tags were the classification label. Additionally, we used a label encoder so that the tags would be mapped to numerical values. Tokenization was applied on input-output pairs where they were divided into training and testing subsets.

Literature Review
According to a study conducted in 2022 [1], natural language processing has greatly benefitted chatbot development. Pattern matching is a very common technique that is typically used in chatbots. Some other techniques mentioned are Deep Face Recognition, Parsin, Deep Learning, Dlib, NLP, AIML and more. The paper focuses on how chatbots have tremendously evolved overtime, with ELIZA being invented in 1966, ALICE in 1995, and Siri in 2011. These technologies have paved the way for even more advanced models to be created, enabling easier communication between users and devices. Likewise, with the development of emotional artificial intelligence, these bots will soon be able to connect with the user on a much more personal level and provide them with emotional support.
The open-domain chatbot research [2] has advanced significantly through scaling models and refinding training data, but it also depends on blending key conversational skills such as empathy, personality, and knowledge to achieve success. The Blended Skill Talk (BST) framework improved engagement and reduces undesirable traits. Response generation strategies, particularly the tuning of beam search parameters, impact chatbot performance through balancing dull and verbose responses. Despite progress, challenges remain, including shallow responses, repetition, and lack of deep knowledge. Future research should refind hybrid models, improve evaluation methods, and enhance response diversity for more human-like interactions.
 
 Methods
The existing work we used is simple Feedforward Neural Network (FNN) with a Bag-of-Words (BoW) approach which includes Bag-of-Words for Text Representation, Dense Neural Network with 3 Layers, Softmax Activation for Classification and SGD Optimizer with Momentum.  Each sentence is tokenized and lemmatized and then BoW is used to convert sentences into a fixed-size vector with each element using 1’s and 0’s to represent whether or not a specific word is present. The input layer matches the vector size and there’s two hidden dense layers. Dropout layers are included which are meant to reduce overfitting. The last layer uses softmax activation to give a probability score for each intent, which helps the model choose the intent that fits best. This method provides a simple and efficient approach, but lacks the ability to capture word order and contextual dependencies in the input sequences. The BoW approach ignores grammar and the positioning of words, which we found limits the model’s understanding. Additionally, even though dropout layers were used to help prevent overfitting, the model still struggled with it. As shown in Figures 1, 2, and 3, the results of the existing methods were poor. The test loss curve was heading in the upwards direction, which signifies that there was overfitting. Also, the accuracy and losses had bad scores, and we wanted the training time to be quicker. Figure 4 shows that the Chatbot response time was increasing with each interaction. So, we decided to implement more methods, such as BiGRU + CNN and dynamic equalization to improve our results.
Yet, we improved the training method as well. We used an intent classification method based on a BiGRU-CNN architecture combined with synonym-based data augmentation and dynamic post-training quantization which resulted in the epochs running faster and getting better loss and accuracy. The model processes input sentence vectors through a BiGRU to capture contextual dependencies. The sequential features are then passed through a 1D convolutional layer to extract local n-gram-like patterns, followed by max pooling and a fully connected layer for classification.


